# -*- coding: utf-8 -*-
"""Vgg19_BharatNatyam_Mudra_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Cn7nAOO_kAE1FazUwuCUksgEHKiXn7E
"""

# ============================================
# ‚ö° QUICK TRAINING VERSION (under 10 minutes)
# Bharatnatyam Mudra Classifier using VGG19
# ============================================

# --------------------------------------------
# 1Ô∏è‚É£ Mount Drive
# --------------------------------------------
from google.colab import drive
drive.mount('/content/drive')

# --------------------------------------------
# 2Ô∏è‚É£ Imports
# --------------------------------------------
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG19
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import json
import os

# --------------------------------------------
# 3Ô∏è‚É£ Dataset Path (choose one)
# --------------------------------------------
# üëâ Right-hand one-hand mudras
data_dir = "/content/drive/MyDrive/Bharatnatyam-Mudras-project/Bharatanatyam-Mudra-Dataset-master/Right Mudras/ONE-HAND MUDRAS"
model_name = "quick_vgg19_right"

# üëâ OR Wrong-hand one-hand mudras
# data_dir = "/content/drive/MyDrive/Bharatnatyam-Mudras-project/Bharatanatyam-Mudra-Dataset-master/Wrong Mudras/Wrong One-Hand Mudras"
# model_name = "quick_vgg19_wrong"

# --------------------------------------------
# 4Ô∏è‚É£ Quick Data Generator (simple + small)
# --------------------------------------------
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_data = datagen.flow_from_directory(
    data_dir,
    target_size=(224,224),
    batch_size=16,          # smaller batch = less GPU memory
    class_mode='categorical',
    subset='training'
)

val_data = datagen.flow_from_directory(
    data_dir,
    target_size=(224,224),
    batch_size=16,
    class_mode='categorical',
    subset='validation'
)

# --------------------------------------------
# 5Ô∏è‚É£ Build Lightweight VGG19 Model
# --------------------------------------------
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))
for layer in base_model.layers:
    layer.trainable = False  # freeze all layers

x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)      # reduced layer size
x = Dropout(0.4)(x)
output = Dense(train_data.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# --------------------------------------------
# 6Ô∏è‚É£ Early Stopping (stops if no improvement)
# --------------------------------------------
callbacks = [EarlyStopping(patience=3, restore_best_weights=True)]

# --------------------------------------------
# 7Ô∏è‚É£ Train (only 8‚Äì10 epochs)
# --------------------------------------------
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=10,              # quick run
    callbacks=callbacks,
    verbose=1
)

# --------------------------------------------
# 8Ô∏è‚É£ Save Model + Labels
# --------------------------------------------
save_path = f"/content/drive/MyDrive/{model_name}.h5"
model.save(save_path)

with open(f"/content/drive/MyDrive/{model_name}_labels.json", "w") as f:
    json.dump(train_data.class_indices, f)

print(f"‚úÖ Model & labels saved in Drive as: {model_name}.h5")

# --------------------------------------------
# 9Ô∏è‚É£ Quick Plot
# --------------------------------------------
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy')
plt.legend()
plt.show()

# Evaluate accuracy and loss
val_loss, val_acc = model.evaluate(val_data)
print(f"‚úÖ Final Validation Accuracy: {val_acc*100:.2f}%")
print(f"üìâ Final Validation Loss: {val_loss:.4f}")

from sklearn.metrics import classification_report
import numpy as np

# Get predictions
Y_pred = model.predict(val_data)
y_pred = np.argmax(Y_pred, axis=1)

# Map correct class indices
labels = (val_data.class_indices)
labels = dict((v,k) for k,v in labels.items())  # reverse mapping

# Correct classification report
print(classification_report(val_data.classes, y_pred, target_names=[labels[i] for i in range(len(labels))]))

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# üîπ Get predictions
Y_pred = model.predict(val_data)
y_pred = np.argmax(Y_pred, axis=1)

# üîπ Reverse the label mapping (index ‚Üí class name)
label_map = {v: k for k, v in val_data.class_indices.items()}

# üîπ Create correct ordered target names
target_names = [label_map[i] for i in range(len(label_map))]

# üîπ Generate fixed report
report = classification_report(
    val_data.classes, y_pred, target_names=target_names, output_dict=True
)

# Convert to DataFrame for a clear table view
report_df = pd.DataFrame(report).transpose()
display(report_df.head(10))  # show first few classes

# üîπ Confusion matrix (optional visualization)
cm = confusion_matrix(val_data.classes, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, cmap='Blues', xticklabels=target_names, yticklabels=target_names)
plt.title("Mudra Confusion Matrix (Fixed)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# ============================================
# üå∏ Fine-Tune VGG19 for Better Mudra Accuracy
# ============================================

# Unfreeze last few layers for fine-tuning
for layer in model.layers[-8:]:
    layer.trainable = True

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Retrain (5‚Äì10 epochs)
history_fine = model.fit(
    train_data,
    validation_data=val_data,
    epochs=10,
    verbose=1
)

# Evaluate after fine-tuning
val_loss, val_acc = model.evaluate(val_data)
print(f"üå∫ Fine-tuned Validation Accuracy: {val_acc*100:.2f}%")
print(f"üìâ Fine-tuned Validation Loss: {val_loss:.4f}")

model.save("/content/drive/MyDrive/fine_tuned_vgg19_right_mudras.h5")
print("‚úÖ Fine-tuned model saved!")

import random, glob

test_images = random.sample(glob.glob("/content/drive/MyDrive/Bharatnatyam-Mudras-project/Bharatanatyam-Mudra-Dataset-master/Right Mudras/ONE-HAND MUDRAS/*/*"), 5)

for img_path in test_images:
    img = image.load_img(img_path, target_size=(224,224))
    x = np.expand_dims(image.img_to_array(img)/255.0, axis=0)
    pred = model.predict(x)
    pred_class = label_names[np.argmax(pred)]
    confidence = np.max(pred)*100
    print(f"ü™∑ {os.path.basename(img_path)} ‚Üí {pred_class} ({confidence:.2f}%)")

import random, glob, os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import json

# -----------------------------
# Load model & label map
# -----------------------------
model_path = "/content/drive/MyDrive/fine_tuned_vgg19_right_mudras.h5"
label_path = "/content/drive/MyDrive/quick_vgg19_right_labels.json"

model = tf.keras.models.load_model(model_path)
with open(label_path, "r") as f:
    labels = json.load(f)
label_names = list(labels.keys())

# -----------------------------
# Randomly pick mudra images
# -----------------------------
image_paths = glob.glob("/content/drive/MyDrive/Bharatnatyam-Mudras-project/Bharatanatyam-Mudra-Dataset-master/Right Mudras/ONE-HAND MUDRAS/*/*.jpg")
test_images = random.sample(image_paths, 3)  # Pick 3 random images

# -----------------------------
# Predict & visualize each
# -----------------------------
for img_path in test_images:
    # Load and preprocess
    img = image.load_img(img_path, target_size=(224,224))
    x = np.expand_dims(image.img_to_array(img)/255.0, axis=0)
    preds = model.predict(x)[0]

    # Get Top 3 predictions
    top_indices = preds.argsort()[-3:][::-1]
    top_labels = [label_names[i] for i in top_indices]
    top_conf = [preds[i]*100 for i in top_indices]

    # Display image + chart
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    plt.imshow(image.load_img(img_path))
    plt.axis('off')
    plt.title(f"ü™∑ {os.path.basename(img_path)}")

    plt.subplot(1,2,2)
    plt.barh(top_labels[::-1], top_conf[::-1], color='teal')
    plt.xlabel("Confidence (%)")
    plt.title("Top 3 Predicted Mudras")
    plt.tight_layout()
    plt.show()

    print(f"‚úÖ Predicted: {top_labels[0]} ({top_conf[0]:.2f}%)\n")

import requests

url = "https://www.natyasutraonline.com/picturegallery/large/pataka.webp"  # paste your image URL here
img_path = "/content/random_web_image.jpg"

r = requests.get(url, stream=True)
if r.status_code == 200:
    with open(img_path, "wb") as f:
        f.write(r.content)
print("‚úÖ Image downloaded:", img_path)

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import json

# Load model & labels
model = tf.keras.models.load_model("/content/drive/MyDrive/fine_tuned_vgg19_right_mudras.h5")
with open("/content/drive/MyDrive/quick_vgg19_right_labels.json", "r") as f:
    labels = json.load(f)
label_names = list(labels.keys())

# Preprocess the uploaded/downloaded image
img = image.load_img(img_path, target_size=(224,224))
x = np.expand_dims(image.img_to_array(img)/255.0, axis=0)

# Predict
pred = model.predict(x)[0]
top_indices = pred.argsort()[-3:][::-1]
top_labels = [label_names[i] for i in top_indices]
top_conf = [pred[i]*100 for i in top_indices]

# Visualize
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.imshow(image.load_img(img_path))
plt.axis("off")
plt.title("ü™∑ Uploaded Mudra")

plt.subplot(1,2,2)
plt.barh(top_labels[::-1], top_conf[::-1], color='teal')
plt.xlabel("Confidence (%)")
plt.title("Top 3 Predicted Mudras")
plt.tight_layout()
plt.show()

print(f"‚úÖ Predicted Mudra: {top_labels[0]} ({top_conf[0]:.2f}%)")
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13708498,"sourceType":"datasetVersion","datasetId":8720706}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"dataset_root = '/kaggle/input/bharatnatyam-mudra-dataset-entire'\nprint(\"Contents:\")\nfor subfolder in os.listdir(dataset_root):\n    print(subfolder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T20:04:40.870055Z","iopub.execute_input":"2025-11-12T20:04:40.870615Z","iopub.status.idle":"2025-11-12T20:04:40.880246Z","shell.execute_reply.started":"2025-11-12T20:04:40.870564Z","shell.execute_reply":"2025-11-12T20:04:40.879699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_root = '/kaggle/input/bharatnatyam-mudra-dataset-entire/Bharatanatyam-Mudra-Dataset-master'\nprint(\"Subfolders:\")\nfor f in os.listdir(dataset_root):\n    print(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T20:05:03.715227Z","iopub.execute_input":"2025-11-12T20:05:03.715474Z","iopub.status.idle":"2025-11-12T20:05:03.731797Z","shell.execute_reply.started":"2025-11-12T20:05:03.715456Z","shell.execute_reply":"2025-11-12T20:05:03.730958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\none_hand_path = os.path.join(dataset_root, 'ONE-HAND MUDRAS')\none_hand_classes = [d for d in os.listdir(one_hand_path) if os.path.isdir(os.path.join(one_hand_path, d))]\nprint(f\"ONE-HAND MUDRAS classes ({len(one_hand_classes)}):\")\nfor cls in one_hand_classes:\n    print(cls)\n\nprint(\"\\nImage count per class (ONE-HAND MUDRAS):\")\nfor cls in one_hand_classes:\n    cls_folder = os.path.join(one_hand_path, cls)\n    img_files = [f for f in os.listdir(cls_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n    print(f\"{cls}: {len(img_files)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T20:05:19.042361Z","iopub.execute_input":"2025-11-12T20:05:19.043140Z","iopub.status.idle":"2025-11-12T20:05:19.525763Z","shell.execute_reply.started":"2025-11-12T20:05:19.043111Z","shell.execute_reply":"2025-11-12T20:05:19.525141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\nroot = \"/kaggle/input/bharatnatyam-mudra-dataset-entire/Bharatanatyam-Mudra-Dataset-master\"\n\none_hand_dir = os.path.join(root, \"ONE-HAND MUDRAS\")\nright_dir = os.path.join(root, \"Right Mudras\")\nwrong_dir = os.path.join(root, \"Wrong Mudras\")\nwrong_onehand_dir = os.path.join(root, \"Wrong One-Hand Mudras\")\n\nclean_root = \"/kaggle/working/clean_mudra_dataset\"\nos.makedirs(clean_root, exist_ok=True)\n\n# Helper to copy images\ndef copy_all(src, dest):\n    os.makedirs(dest, exist_ok=True)\n    for f in os.listdir(src):\n        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            shutil.copy(os.path.join(src, f), dest)\n\n\nprint(\"üöÄ Building unified clean mudra dataset...\\n\")\n\n# 1Ô∏è‚É£ Copy TRUE mudras\nfor cls in os.listdir(one_hand_dir):\n    src = os.path.join(one_hand_dir, cls)\n    if os.path.isdir(src):\n        dest = os.path.join(clean_root, cls)\n        copy_all(src, dest)\n        print(\"‚úî Copied:\", cls)\n\n# 2Ô∏è‚É£ Copy WRONG mudras ‚Üí name them with _WRONG\ndef copy_wrong(src_dir):\n    for cls in os.listdir(src_dir):\n        src = os.path.join(src_dir, cls)\n        if os.path.isdir(src):\n            wrong_name = cls + \"_WRONG\"\n            dest = os.path.join(clean_root, wrong_name)\n            copy_all(src, dest)\n            print(\"‚ùå Copied wrong:\", wrong_name)\n\ncopy_wrong(wrong_onehand_dir)\ncopy_wrong(wrong_dir)\ncopy_wrong(right_dir)\n\nprint(\"\\nüéâ Clean dataset created at:\", clean_root)\nprint(\"Classes found:\", os.listdir(clean_root))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:09:37.024383Z","iopub.execute_input":"2025-11-13T07:09:37.024638Z","iopub.status.idle":"2025-11-13T07:10:20.153286Z","shell.execute_reply.started":"2025-11-13T07:09:37.024607Z","shell.execute_reply":"2025-11-13T07:10:20.152684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Training and saving the model","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# NEW CLEAN DATASET\ndata_dir = \"/kaggle/working/clean_mudra_dataset\"\nmodel_name = \"final_vgg19_mudra_classifier\"\n\n# Data generator\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    rotation_range=20,\n    zoom_range=0.15,\n    shear_range=0.15,\n    width_shift_range=0.10,\n    height_shift_range=0.10,\n    horizontal_flip=True\n)\n\ntrain_data = datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\nval_data = datagen.flow_from_directory(\n    data_dir,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False\n)\n\n# Model\nbase_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.4)(x)\noutput = Dense(train_data.num_classes, activation='softmax')(x)\n\nmodel = Model(base_model.input, output)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2)\n]\n\nhistory = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=15,\n    callbacks=callbacks,\n    verbose=1\n)\n\n# Save model + labels\nmodel.save(f\"/kaggle/working/{model_name}.h5\")\n\nwith open(f\"/kaggle/working/{model_name}_labels.json\", \"w\") as f:\n    json.dump(train_data.class_indices, f)\n\nprint(\"\\nüéâ Model saved!\")\nprint(\"Classes:\", train_data.class_indices)\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:10:42.968567Z","iopub.execute_input":"2025-11-13T07:10:42.969033Z","iopub.status.idle":"2025-11-13T07:45:23.398880Z","shell.execute_reply.started":"2025-11-13T07:10:42.969010Z","shell.execute_reply":"2025-11-13T07:45:23.398258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------------------------------\n# üî• Fine-tuning: Unfreeze deeper VGG19 layers\n# -------------------------------------------------------\nfor layer in base_model.layers:\n    if \"block5\" in layer.name or \"block4\" in layer.name:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\nprint(\"üîì Unfrozen layers:\")\nfor layer in model.layers:\n    if layer.trainable:\n        print(\"Trainable:\", layer.name)\n\n# -------------------------------------------------------\n# üîÅ Recompile with a MUCH lower learning rate\n# -------------------------------------------------------\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-5),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# -------------------------------------------------------\n# üöÄ Train again (fine-tuning)\n# -------------------------------------------------------\nfine_tune_history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=12,\n    callbacks=[\n        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2)\n    ],\n    verbose=1\n)\n\n# -------------------------------------------------------\n# üíæ Save fine-tuned model\n# -------------------------------------------------------\nmodel.save(\"/kaggle/working/fine_tuned_vgg19_mudra_classifier.keras\")\nprint(\"üéâ Fine-tuned model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T07:47:08.996587Z","iopub.execute_input":"2025-11-13T07:47:08.997135Z","iopub.status.idle":"2025-11-13T08:16:15.122774Z","shell.execute_reply.started":"2025-11-13T07:47:08.997111Z","shell.execute_reply":"2025-11-13T08:16:15.122081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport json\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\n\n# ---------------------------------------------------------\n# 1Ô∏è‚É£ Load Fine-Tuned Model + Labels\n# ---------------------------------------------------------\nmodel_path = \"/kaggle/working/fine_tuned_vgg19_mudra_classifier.keras\"  # UPDATE if needed\nlabels_path = \"/kaggle/working/final_vgg19_mudra_classifier_labels.json\"\n\nmodel = tf.keras.models.load_model(model_path, compile=False)\n\nwith open(labels_path, \"r\") as f:\n    class_map = json.load(f)\n\n# Reverse mapping {0: \"MudraName\", 1: \"MudraName_WRONG\"...}\nidx_to_class = {v: k for k, v in class_map.items()}\n\nprint(\"‚úÖ Fine-tuned model & label map loaded!\")\n\n\n# ---------------------------------------------------------\n# 2Ô∏è‚É£ Download + Preprocess Image From URL\n# ---------------------------------------------------------\ndef load_image_from_url(url):\n    try:\n        resp = requests.get(url)\n        resp.raise_for_status()\n    except Exception as e:\n        raise ValueError(f\"‚ùå Failed to download image: {e}\")\n\n    img = Image.open(BytesIO(resp.content)).convert(\"RGB\")\n    img = img.resize((224, 224))\n\n    img = np.array(img).astype(\"float32\") / 255.0\n    img = np.expand_dims(img, axis=0)\n\n    return img\n\n\n# ---------------------------------------------------------\n# 3Ô∏è‚É£ Predict Mudra\n# ---------------------------------------------------------\ndef predict_mudra(url):\n    img = load_image_from_url(url)\n\n    preds = model.predict(img)\n    class_id = np.argmax(preds)\n    confidence = preds[0][class_id]\n\n    label = idx_to_class[class_id]\n\n    print(\"\\nüéØ **Prediction Result**\")\n    print(f\"Mudra: {label}\")\n    print(f\"Confidence: {confidence * 100:.2f}%\")\n\n    return label, confidence\n\n\n# ---------------------------------------------------------\n# 4Ô∏è‚É£ Test Run\n# ---------------------------------------------------------\nif __name__ == \"__main__\":\n    # üî• Replace with any mudra image URL\n    image_url = \"https://www.shutterstock.com/image-photo/woman-hand-showing-hamsasyo-hasta-260nw-25102501.jpg\"\n\n    predict_mudra(image_url)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T08:40:43.767475Z","iopub.execute_input":"2025-11-13T08:40:43.768049Z","iopub.status.idle":"2025-11-13T08:40:45.856674Z","shell.execute_reply.started":"2025-11-13T08:40:43.768025Z","shell.execute_reply":"2025-11-13T08:40:45.855933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport json\nimport os\nimport random\nfrom PIL import Image\n\n# ---------------------------------------------------------\n# 1Ô∏è‚É£ Load fine-tuned model + labels\n# ---------------------------------------------------------\nmodel_path = \"/kaggle/working/fine_tuned_vgg19_mudra_classifier.keras\"  # update if needed\nlabels_path = \"/kaggle/working/final_vgg19_mudra_classifier_labels.json\"\ndataset_path = \"/kaggle/working/clean_mudra_dataset\"  # your cleaned dataset\n\nmodel = tf.keras.models.load_model(model_path, compile=False)\n\nwith open(labels_path, \"r\") as f:\n    class_map = json.load(f)\n\n# Reverse mapping: index ‚Üí class name\nidx_to_class = {v: k for k, v in class_map.items()}\n\nprint(\"‚úÖ Model + labels loaded successfully!\")\n\n\n# ---------------------------------------------------------\n# 2Ô∏è‚É£ Preprocess function\n# ---------------------------------------------------------\ndef preprocess(path):\n    img = Image.open(path).convert(\"RGB\")\n    img = img.resize((224, 224))\n    img = np.array(img) / 255.0\n    img = np.expand_dims(img, axis=0)\n    return img\n\n\n# ---------------------------------------------------------\n# 3Ô∏è‚É£ Pick a random image from your dataset\n# ---------------------------------------------------------\ndef get_random_image(dataset_root):\n    # Choose random class folder\n    class_folder = random.choice(os.listdir(dataset_root))\n    folder_path = os.path.join(dataset_root, class_folder)\n\n    # Pick random image inside it\n    image_name = random.choice([\n        f for f in os.listdir(folder_path)\n        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n    ])\n    \n    image_path = os.path.join(folder_path, image_name)\n    return image_path, class_folder\n\n\n# ---------------------------------------------------------\n# 4Ô∏è‚É£ Predict using the model\n# ---------------------------------------------------------\ndef predict_random_image():\n    image_path, true_class = get_random_image(dataset_path)\n    \n    img = preprocess(image_path)\n    preds = model.predict(img)\n\n    class_id = np.argmax(preds)\n    confidence = preds[0][class_id]\n    predicted_label = idx_to_class[class_id]\n\n    print(\"\\nüñºÔ∏è Random Image:\", image_path)\n    print(f\"üìå True Class: {true_class}\")\n    print(f\"üéØ Predicted: {predicted_label}\")\n    print(f\"üî• Confidence: {confidence*100:.2f}%\")\n\n    # Show the image\n    img_display = Image.open(image_path)\n    display(img_display)\n\n    return predicted_label, confidence\n\n\n# ---------------------------------------------------------\n# 5Ô∏è‚É£ Run test\n# ---------------------------------------------------------\npredict_random_image()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:05:34.540025Z","iopub.execute_input":"2025-11-13T09:05:34.540303Z","iopub.status.idle":"2025-11-13T09:05:37.186421Z","shell.execute_reply.started":"2025-11-13T09:05:34.540283Z","shell.execute_reply":"2025-11-13T09:05:37.185193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_data.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:48:01.678086Z","iopub.execute_input":"2025-11-12T22:48:01.678388Z","iopub.status.idle":"2025-11-12T22:48:01.682700Z","shell.execute_reply.started":"2025-11-12T22:48:01.678367Z","shell.execute_reply":"2025-11-12T22:48:01.682027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"URL Prediction ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport json\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\n\n# ---------------------------------------------------------\n# 1Ô∏è‚É£ Load fine-tuned model + labels\n# ---------------------------------------------------------\nmodel_path = \"/kaggle/working/fine_tuned_vgg19_mudra_classifier.keras\"\nlabels_path = \"/kaggle/working/final_vgg19_mudra_classifier_labels.json\"\n\nmodel = tf.keras.models.load_model(model_path, compile=False)\n\nwith open(labels_path, \"r\") as f:\n    class_map = json.load(f)\n\n# Fix for JSON with string keys\nidx_to_class = {int(v): k for k, v in class_map.items()}\n\nprint(\"‚úÖ Model + labels loaded successfully!\")\n\n\n# ---------------------------------------------------------\n# 2Ô∏è‚É£ Preprocess function for URL image\n# ---------------------------------------------------------\ndef preprocess_url_image(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    img = img.resize((224, 224))\n    img = np.array(img) / 255.0\n    img = np.expand_dims(img, axis=0)\n    return img, img.shape\n\n\n# ---------------------------------------------------------\n# 3Ô∏è‚É£ Predict from URL\n# ---------------------------------------------------------\ndef predict_from_url(image_url):\n    try:\n        img, _ = preprocess_url_image(image_url)\n        preds = model.predict(img)\n\n        class_id = np.argmax(preds)\n        confidence = preds[0][class_id]\n        predicted_label = idx_to_class[class_id]\n\n        print(\"\\nüîó Image URL:\", image_url)\n        print(f\"üßø Predicted Mudra: {predicted_label}\")\n        print(f\"üî• Confidence: {confidence*100:.2f}%\")\n\n        # Show the image\n        display(Image.open(BytesIO(requests.get(image_url).content)))\n\n        return predicted_label, confidence\n\n    except Exception as e:\n        print(\"‚ùå Error processing the image:\", e)\n\n\n# ---------------------------------------------------------\n# 4Ô∏è‚É£ Test it!\n# ---------------------------------------------------------\ntest_url = \"https://sulcdn.azureedge.net/content/images/blogs/24043018-7-arala.jpg\"   # üî• put your image URL here\npredict_from_url(test_url)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:55.794104Z","iopub.execute_input":"2025-11-13T09:33:55.794976Z","iopub.status.idle":"2025-11-13T09:33:57.351352Z","shell.execute_reply.started":"2025-11-13T09:33:55.794951Z","shell.execute_reply":"2025-11-13T09:33:57.350620Z"}},"outputs":[],"execution_count":null}]}